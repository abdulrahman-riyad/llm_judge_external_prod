name: Daily LLM Analysis Pipeline

# =============================================================================
# SCHEDULE AND TRIGGERS
# =============================================================================
# Runs daily at 6 AM UTC (10 AM UAE time)
# Can also be triggered manually or via repository_dispatch

on:
  schedule:
    - cron: '0 6 * * *'  # Daily at 6:00 AM UTC
  
  workflow_dispatch:
    inputs:
      departments:
        description: 'Departments to process (comma-separated)'
        required: false
        default: 'MV_Resolvers,CC_Resolvers'
      date:
        description: 'Target date (YYYY-MM-DD, leave empty for yesterday)'
        required: false
        default: ''
      test_limit:
        description: 'Limit conversations per prompt (for testing)'
        required: false
        default: ''
      skip_metrics:
        description: 'Skip metrics calculation'
        required: false
        default: 'false'
        type: boolean

  repository_dispatch:
    types: [run-analysis]

# =============================================================================
# ENVIRONMENT VARIABLES
# =============================================================================
env:
  LLM_EXECUTION_MODE: external_http
  LLM_VERBOSE: 'true'
  LLM_LOG_LEVEL: INFO
  PYTHON_VERSION: '3.11'

# =============================================================================
# JOBS
# =============================================================================
jobs:
  run-analysis:
    name: Run LLM Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hour timeout for large datasets
    
    steps:
      # -----------------------------------------------------------------
      # SETUP
      # -----------------------------------------------------------------
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      # -----------------------------------------------------------------
      # VALIDATE SECRETS
      # -----------------------------------------------------------------
      - name: Validate secrets
        run: |
          echo "üîê Validating required secrets..."
          if [ -z "${{ secrets.OPENAI_API_KEY }}" ]; then
            echo "‚ùå OPENAI_API_KEY is not set"
            exit 1
          fi
          if [ -z "${{ secrets.SNOWFLAKE_ACCOUNT }}" ]; then
            echo "‚ùå SNOWFLAKE_ACCOUNT is not set"
            exit 1
          fi
          if [ -z "${{ secrets.SNOWFLAKE_USER }}" ]; then
            echo "‚ùå SNOWFLAKE_USER is not set"
            exit 1
          fi
          if [ -z "${{ secrets.SNOWFLAKE_PASSWORD }}" ]; then
            echo "‚ùå SNOWFLAKE_PASSWORD is not set"
            exit 1
          fi
          echo "‚úÖ All required secrets are configured"
      
      # -----------------------------------------------------------------
      # RUN PIPELINE
      # -----------------------------------------------------------------
      - name: Run LLM Analysis Pipeline
        env:
          # OpenAI
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          
          # Snowflake connection
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE || 'LLMS_WH' }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE || 'LLM_EVAL' }}
          SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA || 'PUBLIC' }}
          SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE || 'LLM_ROLE' }}
          
          # Pipeline settings
          LLM_DEPARTMENTS: ${{ github.event.inputs.departments || 'MV_Resolvers,CC_Resolvers' }}
          LLM_TARGET_DATE: ${{ github.event.inputs.date }}
          LLM_CALCULATE_METRICS: ${{ github.event.inputs.skip_metrics == 'true' && 'false' || 'true' }}
        run: |
          echo "üöÄ Starting LLM Analysis Pipeline"
          echo "   Departments: $LLM_DEPARTMENTS"
          echo "   Date: ${LLM_TARGET_DATE:-yesterday}"
          echo "   Calculate Metrics: $LLM_CALCULATE_METRICS"
          
          # Build command arguments
          ARGS="--departments ${LLM_DEPARTMENTS//,/ }"
          
          if [ -n "${{ github.event.inputs.date }}" ]; then
            ARGS="$ARGS --date ${{ github.event.inputs.date }}"
          fi
          
          if [ -n "${{ github.event.inputs.test_limit }}" ]; then
            ARGS="$ARGS --test-limit ${{ github.event.inputs.test_limit }}"
          fi
          
          if [ "${{ github.event.inputs.skip_metrics }}" == "true" ]; then
            ARGS="$ARGS --no-metrics"
          fi
          
          echo "   Command: python run_pipeline.py $ARGS"
          echo ""
          
          python run_pipeline.py $ARGS
      
      # -----------------------------------------------------------------
      # ARTIFACT UPLOAD (for debugging)
      # -----------------------------------------------------------------
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs-${{ github.run_id }}
          path: |
            *.log
            logs/
          retention-days: 7
          if-no-files-found: ignore
      
      # -----------------------------------------------------------------
      # NOTIFICATIONS
      # -----------------------------------------------------------------
      - name: Notify on success
        if: success()
        run: |
          echo "‚úÖ Pipeline completed successfully!"
          echo "   Run ID: ${{ github.run_id }}"
          echo "   Triggered by: ${{ github.event_name }}"
      
      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const date = new Date().toISOString().split('T')[0];
            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üö® Daily LLM Analysis Failed - ${date}`,
              body: `## Pipeline Failure Alert
              
              The daily LLM analysis pipeline failed.
              
              **Details:**
              - **Date:** ${date}
              - **Run ID:** ${context.runId}
              - **Triggered by:** ${context.eventName}
              
              **Action Required:**
              Please check the [workflow run](${runUrl}) for details.
              
              **Common Issues:**
              - API rate limits exceeded
              - Snowflake connection timeout
              - Invalid credentials
              
              /cc @data-team`,
              labels: ['pipeline-failure', 'automated']
            });


# =============================================================================
# MANUAL TRIGGER - SINGLE DEPARTMENT
# =============================================================================
  run-single-department:
    name: Run Single Department (Manual)
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.departments != ''
    timeout-minutes: 120
    
    strategy:
      matrix:
        department: ${{ fromJson(format('["{0}"]', join(split(github.event.inputs.departments, ','), '","'))) }}
      fail-fast: false
      max-parallel: 2
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Run department ${{ matrix.department }}
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE || 'LLMS_WH' }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE || 'LLM_EVAL' }}
          LLM_EXECUTION_MODE: external_http
        run: |
          python run_pipeline.py --departments ${{ matrix.department }}
